{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-DataPreparation.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "U4jkpFVbBfBp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Binary Classification \n",
        " In Machine Learning, Classification is a type of Supervised Learning method, where the task is to divide the data samples into predefined groups by a Decision Function. When there are only two groups, it is called Binary Classification.\n",
        " The decision function is learned from a set of labeled samples, which is called Training Data and the process of learning the decision function is called Training."
      ]
    },
    {
      "metadata": {
        "id": "HI7wKvVceuKT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### NOTE:\n",
        "Basicaly this notebook prepared to use within **Google Colab**: https://colab.research.google.com/. \n",
        "\n",
        "The Google Colabatory has **free Tesla K80 GPU** and already prepared to develop deep learning applications.\n",
        "\n",
        "First time opens this notebook, do not forget to enable **Python 3** runtime and **GPU** accelerator in Google Colab **Notebook Settings**. \n"
      ]
    },
    {
      "metadata": {
        "id": "PTstknFGegQK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Setup Project\n",
        "Create workspace and change directory.\n"
      ]
    },
    {
      "metadata": {
        "id": "ewsloDfJee5f",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7f76e79-335c-4e63-d016-6e7b174db594",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634753908,
          "user_tz": -180,
          "elapsed": 1766,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "PROJECT_HOME = '/content/keras-movie-reviews-classification'\n",
        "\n",
        "import os.path\n",
        "if not os.path.exists(PROJECT_HOME):\n",
        "  os.makedirs(PROJECT_HOME)\n",
        "os.chdir(PROJECT_HOME)\n",
        "\n",
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/keras-movie-reviews-classification\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L2RCaiwbmGbN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Project\n",
        "Import GitHub project to workspace."
      ]
    },
    {
      "metadata": {
        "id": "ZSe5_mzWl8ma",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "67dce0f3-3d84-4cf7-f21b-22a215ae6f53",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634767612,
          "user_tz": -180,
          "elapsed": 9498,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Import project and override existing data.\n",
        "!git init .\n",
        "!git remote add -t \\* -f origin https://github.com/alex-agency/keras-movie-reviews-classification.git\n",
        "!git reset --hard origin/master\n",
        "!git checkout\n",
        "\n",
        "!ls -la input"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialized empty Git repository in /content/keras-movie-reviews-classification/.git/\n",
            "Updating origin\n",
            "remote: Counting objects: 16, done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 16 (delta 2), reused 11 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "From https://github.com/alex-agency/keras-movie-reviews-classification\n",
            " * [new branch]      master     -> origin/master\n",
            "HEAD is now at 9361c0f step2-data-preparation\n",
            "total 34888\n",
            "drwxr-xr-x 3 root root     4096 Apr 13 15:52 .\n",
            "drwxr-xr-x 4 root root     4096 Apr 13 15:52 ..\n",
            "drwxr-xr-x 4 7297 1000     4096 Jun 26  2011 aclImdb\n",
            "-rw-r--r-- 1 root root 16338527 Apr 13 15:52 dataset.npz\n",
            "-rw-r--r-- 1 root root 19372046 Apr 13 15:52 reviews.tsv.bz2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XUrEe1jsnNMd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Movie Review text data\n",
        "Create Data Frame from compressed csv file."
      ]
    },
    {
      "metadata": {
        "id": "7MKcaxkipKON",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "398f3e10-ba46-4743-ddd6-d26d6046a5ac",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634781438,
          "user_tz": -180,
          "elapsed": 4533,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import sklearn.utils\n",
        "import pandas as pd\n",
        "\n",
        "# Import Data frame from compressed tsv file\n",
        "reviews_df = pd.read_csv(\"input/reviews.tsv.bz2\", sep='\\t', \n",
        "                         encoding='utf-8', compression='bz2')\n",
        "# Shuffle all reviews\n",
        "reviews_df = sklearn.utils.shuffle(reviews_df)\n",
        "\n",
        "print(\"Review Frame:\")\n",
        "print(reviews_df.head())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review Frame:\n",
            "                                                  review  feedback\n",
            "49935  This movie was so bad, I thought I was going t...  negative\n",
            "2366   Let's start this review out on a positive note...  positive\n",
            "13543  I'm glad that I saw this film after Mr.Sandler...  negative\n",
            "29566  This version of ALICE IN WONDERLAND is truly o...  positive\n",
            "37164  Although the concept of a 32 year old woman po...  positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y-YXXsj-A_28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Keras\n",
        "Keras is a high-level API, written in Python and capable of running on top of TensorFlow, Theano, or CNTK deep learning frameworks.\n",
        "\n",
        "Keras provides a simple and modular API to create and train Neural Networks, hiding most of the complicated details under the hood.\n",
        "By default, Keras is configured to use Tensorflow as the backend since it is the most popular choice.\n",
        "\n",
        "Keras is becoming super popular recently because of its simplicity."
      ]
    },
    {
      "metadata": {
        "id": "rcQa7qPNwxdp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a989e95-ccf4-45f3-ce01-a53094abc9e3",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634793293,
          "user_tz": -180,
          "elapsed": 7713,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Load Keras libraries\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "y3c1agXxPD5H",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data transformation\n",
        "Original data is in text format. In order to be able to feed it into a neural network it needs to be converted into tensors first.\n",
        "\n",
        "The first step is tokenizing the reviews. The tokenizer converts each review into a sequence of integers with each integer representing the index of the word in a dictionary. Next the sequences are padded so all of them have the same length."
      ]
    },
    {
      "metadata": {
        "id": "WdFKdkk5ndy4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "62eff520-1df8-40eb-dc00-3d23f3918ed1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634850938,
          "user_tz": -180,
          "elapsed": 17484,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "reviews = reviews_df['review']\n",
        "\n",
        "# The words are indexed such that lower indexes correspond to more frequently used words.\n",
        "MAX_NB_WORDS = 5000 # only more frequently used words will be kept\n",
        "\n",
        "# Create tokenizer and set the number of features we want.\n",
        "# The Tokenizer stores everything in the word_index during fit_on_texts. \n",
        "# Then, when calling the texts_to_sequences method, only the top num_words are considered.\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
        "\n",
        "print('Fitting tokenizer...')\n",
        "# Train tokenizer\n",
        "tokenizer.fit_on_texts(reviews)\n",
        "# Review sequence represents each word as a number.\n",
        "# Unknown words or words that are not frequently used are ingored.\n",
        "reviews_seq = tokenizer.texts_to_sequences(reviews)\n",
        "# get vocabluary, which will be used for converting sequence back to review.\n",
        "dictionary = tokenizer.word_index   \n",
        "# cut vocabluary to frequently used words.\n",
        "dictionary = dict(list(dictionary.items())[:MAX_NB_WORDS])\n",
        "\n",
        "print('Vocabulary: {} words.'.format(len(dictionary)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting tokenizer...\n",
            "Vocabulary: 5000 words.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6ImXmXVgGCTi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "cd806f9f-4df5-43ae-d132-87ff429c7755",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634872169,
          "user_tz": -180,
          "elapsed": 407,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Transform sequence of numbers back to text.\n",
        "def sequence_to_text(sequence, dictionary): \n",
        "  text = ''\n",
        "  for index in sequence:\n",
        "    for word, num in dictionary.items():\n",
        "      if num == index:\n",
        "        text = text + ' ' + word\n",
        "        break\n",
        "  return text\n",
        "\n",
        "print('Sequence:')\n",
        "print(reviews_seq[0])\n",
        "\n",
        "print('\\nReview:')\n",
        "print(sequence_to_text(reviews_seq[0], dictionary))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequence:\n",
            "[10, 16, 12, 33, 73, 9, 189, 9, 12, 165, 5, 2052, 7, 1, 650, 4, 8, 8, 12, 28, 9, 97, 76, 5, 845, 139, 8, 1, 452, 4, 1, 16, 116, 32, 22, 29, 294, 12, 2410, 60, 8, 4, 1908, 1972, 1732, 5, 67, 37, 29, 223, 31, 601, 29, 8, 60, 72, 88, 457, 14, 131, 82, 45, 12, 53, 1700, 52, 5, 1, 101, 1, 552, 11, 1487, 9, 469, 12, 1342, 5, 93, 175, 1434, 17, 14, 46, 283, 8, 38, 303, 90, 72, 24, 5, 1640, 5, 346, 99, 346, 4, 4475, 726, 11, 761, 2816, 5, 59, 4, 264, 12, 80, 7, 1, 16, 138, 843, 45, 12, 160, 211, 41, 1, 16, 29, 28, 8, 12, 36, 1240, 139, 1, 87, 4988, 515, 4, 169, 294, 16, 122, 89, 15, 3, 119, 225, 4, 459, 1333, 7, 5, 389, 21, 1399, 11, 8, 12, 165, 5, 75, 125, 1073, 8, 148, 337, 630, 304, 9, 565, 1, 768, 557, 4378, 2067, 141, 25, 318, 14, 263, 5, 1, 607, 2594, 59, 14, 43, 54, 12, 3, 48, 16, 17, 145, 9, 580, 141, 9, 816, 8, 2, 93, 246, 9, 291, 38, 1027, 52, 7, 1, 3380, 272, 9, 12, 17, 9, 405, 291, 1027, 52, 7, 1, 3380, 4, 10, 18, 9, 61, 413, 5, 1, 768, 1682, 5, 36, 10, 16, 9, 234, 3, 724, 248, 4147, 325, 585, 124, 289, 816, 8, 19, 265, 2, 422, 139, 8, 13, 9, 114]\n",
            "\n",
            "Review:\n",
            " this movie was so bad i thought i was going to scream in the middle of it it was all i could do to sit through it the beginning of the movie where they are at war was promising only it of saving private ryan to me or at least an attempt at it only we don't care for these people there was no build up to the characters the kid that dies i guess was suppose to make us cry but for some reason it just everyone then we have to listen to line after line of sappy dialog that tried desperately to which of course was also in the movie go figure there was nothing original about the movie at all it was like sitting through the most mundane parts of every war movie ever made with a little bit of humor thrown in to keep you hoping that it was going to get better sadly it doesn't 3 hours later i leave the theater feeling cheated anthony should be shot for trying to the english patient which for it's time was a good movie but now i wonder should i rent it and make sure i wasn't just caught up in the hype maybe i was but i definitely wasn't caught up in the hype of this film i really went to the theater wanting to like this movie i am a die hard nicole fan save your money rent it on dvd and laugh through it as i did\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u4aX61gZ9xPX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Padding data\n",
        "The next step is to make all of the reviews sequence the same length."
      ]
    },
    {
      "metadata": {
        "id": "z0K5bRuRxLc3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "e956fb87-eccf-4a07-aabb-ee0119705265",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634878608,
          "user_tz": -180,
          "elapsed": 1626,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# Set max review length as 90 percentile of all sequences length.\n",
        "MAX_SEQUENCE_LENGTH = int(round(np.percentile([len(i) for i in reviews_seq], 90)))\n",
        "print('Max sequence length: {} words.'.format(MAX_SEQUENCE_LENGTH))\n",
        "\n",
        "# Padding all text to same size, longer sequences are reduced to max legth.\n",
        "reviews_vectors = pad_sequences(reviews_seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "\n",
        "print('\\nPadded Sequence:')\n",
        "print(reviews_vectors[0])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max sequence length: 400 words.\n",
            "\n",
            "Padded Sequence:\n",
            "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0   10   16   12   33   73    9  189\n",
            "    9   12  165    5 2052    7    1  650    4    8    8   12   28    9\n",
            "   97   76    5  845  139    8    1  452    4    1   16  116   32   22\n",
            "   29  294   12 2410   60    8    4 1908 1972 1732    5   67   37   29\n",
            "  223   31  601   29    8   60   72   88  457   14  131   82   45   12\n",
            "   53 1700   52    5    1  101    1  552   11 1487    9  469   12 1342\n",
            "    5   93  175 1434   17   14   46  283    8   38  303   90   72   24\n",
            "    5 1640    5  346   99  346    4 4475  726   11  761 2816    5   59\n",
            "    4  264   12   80    7    1   16  138  843   45   12  160  211   41\n",
            "    1   16   29   28    8   12   36 1240  139    1   87 4988  515    4\n",
            "  169  294   16  122   89   15    3  119  225    4  459 1333    7    5\n",
            "  389   21 1399   11    8   12  165    5   75  125 1073    8  148  337\n",
            "  630  304    9  565    1  768  557 4378 2067  141   25  318   14  263\n",
            "    5    1  607 2594   59   14   43   54   12    3   48   16   17  145\n",
            "    9  580  141    9  816    8    2   93  246    9  291   38 1027   52\n",
            "    7    1 3380  272    9   12   17    9  405  291 1027   52    7    1\n",
            " 3380    4   10   18    9   61  413    5    1  768 1682    5   36   10\n",
            "   16    9  234    3  724  248 4147  325  585  124  289  816    8   19\n",
            "  265    2  422  139    8   13    9  114]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1fVwRbBBympd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### One-hot vectors\n",
        "Transform feedbacks to one-hot vectors. A one hot encoding is a representation of categorical variables as binary vectors.\n",
        "\n",
        "This first requires that the categorical values be mapped to integer values."
      ]
    },
    {
      "metadata": {
        "id": "5-d_Wv7gyTlp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "cellView": "code",
        "outputId": "af055296-fd39-4002-a6a0-feee5d16d55f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634883047,
          "user_tz": -180,
          "elapsed": 480,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "feedback = reviews_df['feedback']\n",
        "\n",
        "# Convert features to integers.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels = label_encoder.fit_transform(feedback)\n",
        "\n",
        "# Converts a class vector (integers) to binary class matrix.\n",
        "feedback_vectors = to_categorical(labels)\n",
        "\n",
        "print('Shape of reviews tensor:', reviews_vectors.shape)\n",
        "print('Shape of feedbacks tensor:', feedback_vectors.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of reviews tensor: (50000, 400)\n",
            "Shape of feedbacks tensor: (50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Z-wu4vmNA1n3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "4f915988-6163-4b7a-9e24-52f77f1202c1",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634886965,
          "user_tz": -180,
          "elapsed": 489,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from numpy import argmax\n",
        "# Transform one-hot vetor back to label.\n",
        "def onehot_to_text(onehot, encoder): \n",
        "  return encoder.inverse_transform(argmax(onehot))\n",
        "\n",
        "print('One Hot vector: {}'.format(feedback_vectors[0]) )\n",
        "print('Feedback: {}'.format(onehot_to_text(feedback_vectors[0], label_encoder) ))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "One Hot vector: [1. 0.]\n",
            "Feedback: negative\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "P9CoPnDXoyrs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Split data into train and test subsets"
      ]
    },
    {
      "metadata": {
        "id": "fBAb9crT7_gP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "1634cefb-eb77-43f1-8066-a51ea9502267",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634891143,
          "user_tz": -180,
          "elapsed": 491,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split arrays or matrices into random train and test subsets\n",
        "x_train, x_test, y_train, y_test = train_test_split(reviews_vectors, feedback_vectors, test_size = 0.20)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "print('x_test shape:', x_test.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (40000, 400)\n",
            "y_train shape: (40000, 2)\n",
            "x_test shape: (10000, 400)\n",
            "y_test shape: (10000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VZTf08S6MNWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Export result to dataset file\n",
        "Serialize object and put it to compressed numpy array."
      ]
    },
    {
      "metadata": {
        "id": "1cqFRQwQiZf5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "08fee5b1-3d9b-484b-a5d6-3c5276f46f8a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1523634907892,
          "user_tz": -180,
          "elapsed": 6932,
          "user": {
            "displayName": "Alex Z",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "110711877726297594950"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Export data to compressed numpy array\n",
        "np.savez_compressed('input/dataset.npz', dataset=((x_train, y_train), (x_test, y_test)), \n",
        "                    dictionary=dictionary, label_encoder=label_encoder)\n",
        "!ls -la input"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 35696\r\n",
            "drwxr-xr-x 3 root root     4096 Apr 13 15:52 .\r\n",
            "drwxr-xr-x 4 root root     4096 Apr 13 15:52 ..\r\n",
            "drwxr-xr-x 4 7297 1000     4096 Jun 26  2011 aclImdb\r\n",
            "-rw-r--r-- 1 root root 17163254 Apr 13 15:55 dataset.npz\r\n",
            "-rw-r--r-- 1 root root 19372046 Apr 13 15:52 reviews.tsv.bz2\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R1qt-FhknGPK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Downloading file to your local file system\n",
        "\n",
        "It will invoke a browser download of the file to your local computer."
      ]
    },
    {
      "metadata": {
        "id": "vOWD80y7nGPM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "# Download file\n",
        "files.download('input/dataset.npz')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}